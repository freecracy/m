(window.webpackJsonp=window.webpackJsonp||[]).push([[47],{447:function(a,t,r){a.exports=r.p+"assets/img/Loki.5ae6aac4.png"},568:function(a,t,r){"use strict";r.r(t);var s=r(20),e=Object(s.a)({},(function(){var a=this,t=a.$createElement,s=a._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("h1",{attrs:{id:"日志监控"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#日志监控"}},[a._v("#")]),a._v(" 日志监控")]),a._v(" "),s("h2",{attrs:{id:"loki-promtail-grafana"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#loki-promtail-grafana"}},[a._v("#")]),a._v(" Loki/Promtail/Grafana")]),a._v(" "),s("p",[a._v("在 k8s 中 promtail 以 DaemonSet 方式运行在每个节点中,通过 k8s API 等到日志的正确元数据,并将他们发送到 loki")]),a._v(" "),s("p",[a._v("loki 两个组件 Distributor 和 Ingester, Distributor 将日志 Gzip 压缩, Ingester 负责构建和刷新 chunk,当 chunk 到达一定数量后刷新到存储,当日志到达 Distributor 时根据元数据和 hash 算法计算出到达哪个 Ingester 上.刷新一个chunk后 Ingester 创建一个新的 chunk 并将新条目添加到新的 chunk 中.对 chunk 和 index 使用单独的数据库,因为存储数据类型不同.Ingester 虽然是有状态的,当新的节点加入或减少整节点间的 chunk 会重新分配,适应新的散列环.")]),a._v(" "),s("p",[a._v("Querier : 非则给定一个时间和标签选择器, Querier 查看索引以确定哪些块匹配,并通过 greps 将结果显示出来,它还从 Ingester 获取尚未刷新的最新数据.")]),a._v(" "),s("p",[a._v("Loki 的索引存储可以是 cassandra/bigtable/dynamodb,而 chunks 可以是各种对象存储,Querier 和 Distributor 都是无状态的组件.")]),a._v(" "),s("p",[s("img",{attrs:{src:r(447),alt:"Loki"}})]),a._v(" "),s("h2",{attrs:{id:"全链路监控"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#全链路监控"}},[a._v("#")]),a._v(" 全链路监控")]),a._v(" "),s("p",[a._v("理论基础是 Google Dapper ,包括吞吐量、响应时间、错误记录")]),a._v(" "),s("h3",{attrs:{id:"注意问题"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#注意问题"}},[a._v("#")]),a._v(" 注意问题")]),a._v(" "),s("ol",[s("li",[a._v("监控系统的性能损耗 : 可以全部请求监控也可以采用监控,极端情况下需要关闭跟踪系统")]),a._v(" "),s("li",[a._v("代码侵入 : 对业务方透明,最好业务方无感知")])]),a._v(" "),s("h3",{attrs:{id:"功能模块"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#功能模块"}},[a._v("#")]),a._v(" 功能模块")]),a._v(" "),s("ol",[s("li",[a._v("埋点与生成日志 : 采样或异步log,不能影响性能,包括traceID、spanID和可扩展字段")]),a._v(" "),s("li",[a._v("日志采集 : 可以增加MQ作为缓存每个机器部署agent进行采集,采集后离线分析")]),a._v(" "),s("li",[a._v("分析统计 : 把同一traceID的span收集起来按timeline排序,把parentID串起来就是调用栈")])]),a._v(" "),s("h3",{attrs:{id:"调用过程追踪"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#调用过程追踪"}},[a._v("#")]),a._v(" 调用过程追踪")]),a._v(" "),s("ol",[s("li",[a._v("请求到来生成一个TraceID通过TraceID可以串联起整个调用链,一个TraceID代表一次请求")]),a._v(" "),s("li",[a._v("除了TraceID还需要SpanID用于记录调用父子关系,每个服务都会记录parentID和spanID,通过他们可以组织一次完整调用链父子关系")]),a._v(" "),s("li",[a._v("一个没有TraceID的Span看作root span当做调用链入口")]),a._v(" "),s("li",[a._v("所有这些ID可以全局唯一的64位整数表示")]),a._v(" "),s("li",[a._v("整个调用过程透传TranceID和SpanID")]),a._v(" "),s("li",[a._v("每个服务将这次请求附带的TrancdID和SpanID作为parentID记录下来,将自己生成的SpanID也记录下来")]),a._v(" "),s("li",[a._v("只需要根据TraceID查所有调用记录,然后根据parentID和spanID组织整个调用父子关系")])]),a._v(" "),s("h2",{attrs:{id:"分布式调用链追踪系统"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#分布式调用链追踪系统"}},[a._v("#")]),a._v(" 分布式调用链追踪系统")]),a._v(" "),s("h3",{attrs:{id:"设计"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#设计"}},[a._v("#")]),a._v(" 设计")]),a._v(" "),s("ol",[s("li",[a._v("trace : 每个调用链的全局唯一 ID,并且在调用链上的每次调用都带上这个 ID,这样每个子调用就关联起来了.")]),a._v(" "),s("li",[a._v("先后次序和父子关系 : 为每个调用分配一个 ID (spanID),并且把这个 ID 传递给子调用,子调用根据 parent span ID 生成自己的 span ID")])]),a._v(" "),s("h3",{attrs:{id:"常用分布式追踪系统"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#常用分布式追踪系统"}},[a._v("#")]),a._v(" 常用分布式追踪系统")]),a._v(" "),s("p",[a._v("SkyWalking、Zipkin、PinPoint ...")]),a._v(" "),s("h2",{attrs:{id:"监控系统基本流程"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#监控系统基本流程"}},[a._v("#")]),a._v(" 监控系统基本流程")]),a._v(" "),s("ol",[s("li",[a._v("数据采集")]),a._v(" "),s("li",[a._v("数据传输")]),a._v(" "),s("li",[a._v("数据存储")]),a._v(" "),s("li",[a._v("数据展示")]),a._v(" "),s("li",[a._v("监控告警")])])])}),[],!1,null,null,null);t.default=e.exports}}]);