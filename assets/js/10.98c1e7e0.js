(window.webpackJsonp=window.webpackJsonp||[]).push([[10],{508:function(s,a,e){s.exports=e.p+"assets/img/rocketMQ-zucheng.66241d46.png"},509:function(s,a,e){s.exports=e.p+"assets/img/RabbitMQ.8b0e7961.png"},510:function(s,a,e){s.exports=e.p+"assets/img/kafka-reactor.54e35ed9.png"},511:function(s,a,e){s.exports=e.p+"assets/img/xiaoxiduilie.23359fa0.png"},644:function(s,a,e){"use strict";e.r(a);var t=e(20),r=Object(t.a)({},(function(){var s=this,a=s.$createElement,t=s._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"消息队列"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息队列"}},[s._v("#")]),s._v(" 消息队列")]),s._v(" "),t("h2",{attrs:{id:"比较"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#比较"}},[s._v("#")]),s._v(" 比较")]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("MQ")]),s._v(" "),t("th",[s._v("ActiveMQ")]),s._v(" "),t("th",[s._v("RabbitMQ")]),s._v(" "),t("th",[s._v("RocketMQ")]),s._v(" "),t("th",[s._v("kafka")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("语言")]),s._v(" "),t("td",[s._v("java")]),s._v(" "),t("td",[s._v("rtlang")]),s._v(" "),t("td",[s._v("java")]),s._v(" "),t("td",[s._v("java")])]),s._v(" "),t("tr",[t("td",[s._v("社区")]),s._v(" "),t("td"),s._v(" "),t("td"),s._v(" "),t("td",[s._v("阿里(捐赠 apache)")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("界面")]),s._v(" "),t("td",[s._v("web")]),s._v(" "),t("td",[s._v("web")]),s._v(" "),t("td",[s._v("只有命令行")]),s._v(" "),t("td",[s._v("web")])]),s._v(" "),t("tr",[t("td",[s._v("延迟")]),s._v(" "),t("td",[s._v("毫秒")]),s._v(" "),t("td",[s._v("微妙")]),s._v(" "),t("td",[s._v("毫秒")]),s._v(" "),t("td",[s._v("毫秒")])]),s._v(" "),t("tr",[t("td",[s._v("吞吐量")]),s._v(" "),t("td",[s._v("w")]),s._v(" "),t("td",[s._v("w")]),s._v(" "),t("td",[s._v("10w")]),s._v(" "),t("td",[s._v("10w")])])])]),s._v(" "),t("h2",{attrs:{id:"rocketmq"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rocketmq"}},[s._v("#")]),s._v(" RocketMQ")]),s._v(" "),t("h3",{attrs:{id:"概念"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#概念"}},[s._v("#")]),s._v(" 概念")]),s._v(" "),t("p",[s._v("topic、生产者、消费者、消息、group 同 kafka,自己实现了服务发现服务 namesrv.")]),s._v(" "),t("h3",{attrs:{id:"作用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#作用"}},[s._v("#")]),s._v(" 作用")]),s._v(" "),t("p",[s._v("异步、解藕、削峰填谷、分布式事务最终一致性、数据分发(比如 binlog)")]),s._v(" "),t("h3",{attrs:{id:"组件"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#组件"}},[s._v("#")]),s._v(" 组件")]),s._v(" "),t("p",[t("img",{attrs:{src:e(508),alt:"rocketMQ-zucheng"}})]),s._v(" "),t("ol",[t("li",[s._v("name server : 无状态节点,可集群部署,此处提供命名服务,更新和发现 broker 服务,本质是一个注册中心.")]),s._v(" "),t("li",[s._v("broker : 消息中转角色,负责存储转发消息,分为 master 和 slave,启动时将自己注册到 name server,之后每 30s 向 name server 上报 topic 路由信息.")]),s._v(" "),t("li",[s._v("生产者 : 与 name server 集群中随机一个节点建立长连接(keep-alive),定期从 name server 读取 topic 路由信息,并向提供 topic 服务的 master broker 建立长连接,且定时向 master broker 发送心跳.")]),s._v(" "),t("li",[s._v("消费者 : 与 name server 集群中随机一个节点建立长连接,定期从 name server 拉取 topic 路由信息,并向提供 topic 服务的 master broker、slave broker 建立长连接,且定时向 master broker、slave broker 发送心跳.消费者既可以从 master broker 订阅消息,也可以从 slave broker 订阅消息,订阅规则由 broker 配置决定.")])]),s._v(" "),t("h3",{attrs:{id:"消息类型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息类型"}},[s._v("#")]),s._v(" 消息类型")]),s._v(" "),t("ol",[t("li",[s._v("普通消息\n"),t("ul",[t("li",[s._v("同步发送 : 消息发送方发出一条消息,会同步得到服务端返回结果")]),s._v(" "),t("li",[s._v("异步发送 : 消息发送方发出一条消息不用等待服务端返回结果,接着发送下一条消息,发送方可以通过回调接口接收服务端响应")]),s._v(" "),t("li",[s._v("单向发送 : 消息发送方只负责发送消息,发送消息快,存在丢失消息风险")])])]),s._v(" "),t("li",[s._v("顺序消息")]),s._v(" "),t("li",[s._v("定时消息(延迟消息) : 消费发送到服务端后,不会立即投递给消费者,而是等到消息指定的时间后才会投递消费者进行消费,延迟消息一般是在当前发送时间的基础上延迟多久发送.")]),s._v(" "),t("li",[s._v("事务消息")])]),s._v(" "),t("h3",{attrs:{id:"事务消息"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#事务消息"}},[s._v("#")]),s._v(" 事务消息")]),s._v(" "),t("p",[s._v("两阶段提交结合消息反查机制确保最终一致性.")]),s._v(" "),t("ol",[t("li",[s._v("发送方发送半事务消息到服务端")]),s._v(" "),t("li",[s._v("服务端接收消息后,消息持久化成功,向发送方返回 ack 确认消息已经发送成功,此时消息为半事务消息,不会投递给消费方")]),s._v(" "),t("li",[s._v("收到半事务消息的 ack 后,发送方开始执行本地事务逻辑")]),s._v(" "),t("li",[s._v("发送方根据本地事务执行结果向服务端提交二次确认,如果本地事务执行成功则进行消息的 commit,如果执行失败则进行消息的 rollback,服务端收到 commit 状态则将半事务消息标记为可投递,服务端收到 rollback 状态则删除半事务消息.")]),s._v(" "),t("li",[s._v("如果没有进行消息的二次确认,等待固定时间后服务端将对消息发起消息回查")]),s._v(" "),t("li",[s._v("发送方收到消息回查后需要检查对应消息本地事务执行结果.根据检查到的本地事务的最终状态再次提交二次确认.")])]),s._v(" "),t("h3",{attrs:{id:"消息重试"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息重试"}},[s._v("#")]),s._v(" 消息重试")]),s._v(" "),t("p",[s._v("消息在消费方消费失败后,服务端会重新投递消息,直到消费者成功消费消息,默认重试 16 次.")]),s._v(" "),t("h3",{attrs:{id:"消息过滤"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息过滤"}},[s._v("#")]),s._v(" 消息过滤")]),s._v(" "),t("p",[s._v("可以给消息指定 tag,通过 tag 来区分消息类型,消费者可以根据 tag 在服务端完成消息过滤,确保消费者最终只能消费到其关注的消息.")]),s._v(" "),t("h3",{attrs:{id:"消费模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消费模式"}},[s._v("#")]),s._v(" 消费模式")]),s._v(" "),t("ol",[t("li",[s._v("集群消费 : 消息只允许被消费一次")]),s._v(" "),t("li",[s._v("广播消费 : 会让每个消费者都消费一次,如使用了本地缓存,当数据变更时需要刷新每个节点本地缓存.")])]),s._v(" "),t("h3",{attrs:{id:"消息幂等"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息幂等"}},[s._v("#")]),s._v(" 消息幂等")]),s._v(" "),t("p",[s._v("最佳的幂等处理方式需要唯一业务标识,在发送消息时可以为每个消息设置一个 key 用来做业务的唯一标识.")]),s._v(" "),t("h3",{attrs:{id:"本地事务消息封装"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#本地事务消息封装"}},[s._v("#")]),s._v(" 本地事务消息封装")]),s._v(" "),t("p",[s._v("如果每个业务场景都去实现一个反查逻辑,不易使用.本地事务消息表,本地事务消息需要在服务对应数据库创建一个消息表,发送消息时不是真正把消息发送给 MQ,而是往消息表中插入一条消息数据.插入动作跟本地业务逻辑是同一个事务,如果本地事务执行成功,消息才会落表成功,才会发送给 MQ,本地事务失败消息回滚.然后启动一个专门的线程去拉取消息表中未发送的消息投递给 MQ,如果投递失败可以一直重试,直到成功或者人工介入.")]),s._v(" "),t("p",[s._v("消息写到消息表,然后一直给 MQ 发送,不会有问题,如果 MQ 收到消息消息还在 pagecache 中 broker 宕机了,会出现消息丢失,当然可以使用同步刷盘避免丢失.在消息表中标记未发送、已发送、已消费.当消息还是未发送的时候就会被发送到 MQ,如果发送成功了,状态就是已发送,如果发送成功了状态就是已发送,但是几分钟后状态还是已发送就知道消息丢失或者消费速度跟不上生产速度,消息堆积了.")]),s._v(" "),t("h3",{attrs:{id:"死信队列"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#死信队列"}},[s._v("#")]),s._v(" 死信队列")]),s._v(" "),t("h2",{attrs:{id:"rabbitmq"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rabbitmq"}},[s._v("#")]),s._v(" RabbitMQ")]),s._v(" "),t("p",[s._v("一个erlang开发的MQ,一个队列,消息确认后删除,开发者定义命名队列,发布者可以向队列发送消息,消费者通过命名队列消费消息.使用消息交换器来实现发布订阅,发布者将消息发布到消息交换器上,不用知道有哪些订阅者.每一个订阅了交换器的消费者都会创建一个队列,消息交换器会把生产的消息放入队列,供消费者消费,消息交换器也可以基于路由规则为订阅者过滤消息.RabbitMQ支持临时和持久两种订阅类型.消费者也可以分订阅者组消费.")]),s._v(" "),t("p",[t("img",{attrs:{src:e(509),alt:"RabbitMQ"}})]),s._v(" "),t("p",[s._v("当一个消息没有任何消费者消费就会成为死信,被重新 push 到另一个 exchange.这个 exchange 就是死信队列.通过 exchange 将消息发送到多个队列可以使一条消息被多个消费者消费.")]),s._v(" "),t("h3",{attrs:{id:"集群模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#集群模式"}},[s._v("#")]),s._v(" 集群模式")]),s._v(" "),t("ol",[t("li",[s._v("主备模式 : 从节点不提供任何读写服务,只做备份,主宕机备会自动切换主节点.(区别主从,主提供写从提供读)")]),s._v(" "),t("li",[s._v("集群模式 : 镜像队列,多活模式")])]),s._v(" "),t("h2",{attrs:{id:"rocketmq-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rocketmq-2"}},[s._v("#")]),s._v(" RocketMQ")]),s._v(" "),t("p",[s._v("阿里开源,支持事务消息")]),s._v(" "),t("h3",{attrs:{id:"事务消息-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#事务消息-2"}},[s._v("#")]),s._v(" 事务消息")]),s._v(" "),t("ol",[t("li",[s._v("发送半消息(发送到消息队列,但是不投递,不能被消费)")]),s._v(" "),t("li",[s._v("执行本地事务")]),s._v(" "),t("li",[s._v("发送commit或rollback")]),s._v(" "),t("li",[s._v("提供回查接口(commit、rollback失败或丢失后回查) : 业务侵入(解决方法,封装客户端本地增加事务消息表,定期扫库发送和清理,优化写库完成后直接在内存中投递消息)")])]),s._v(" "),t("h2",{attrs:{id:"kafka"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka"}},[s._v("#")]),s._v(" kafka")]),s._v(" "),t("ol",[t("li",[s._v("producer")]),s._v(" "),t("li",[s._v("broker")]),s._v(" "),t("li",[s._v("topic")]),s._v(" "),t("li",[s._v("partition : partition 的表现形式就是一个一个文件夹")]),s._v(" "),t("li",[s._v("replication")]),s._v(" "),t("li",[s._v("consumer : 如果消费者大于 partition 数量,多出来的消费者不消费任何数据")]),s._v(" "),t("li",[s._v("consumer group : 一个分区的数据只能被消费者组中某一个消费者消费,同一个消费者组的消费者可以消费同一个 topic 不同分区的数据")])]),s._v(" "),t("p",[s._v("是一种分布式流系统,一般做MQ使用,是根据预先配置好的时间来保留分区中的消息,而不是根据消费者是否消费了这些消息.保留机制可以使消费者自由重读之前的消息.同过删除 partition 下的 segment 来删除消息.")]),s._v(" "),t("p",[s._v("持久订阅 : 在重启之后不会丢失偏移")]),s._v(" "),t("p",[s._v("临时订阅 : 重启后丢失偏移并且每次重启之后都会从分区中最新记录开始读取")]),s._v(" "),t("h3",{attrs:{id:"消费流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消费流程"}},[s._v("#")]),s._v(" 消费流程")]),s._v(" "),t("ol",[t("li",[s._v("producer 先从集群获取分区的 leader")]),s._v(" "),t("li",[s._v("producer 将消息发送给 leader")]),s._v(" "),t("li",[s._v("leader 将消息写入本地文件")]),s._v(" "),t("li",[s._v("followers 从 leader pull 消息")]),s._v(" "),t("li",[s._v("followers 将消息写入本地后向 leader 发送 ack")]),s._v(" "),t("li",[s._v("leader 收到所有副本的 ack 后向 producer 发送 ack")])]),s._v(" "),t("h3",{attrs:{id:"为什么副本不提供读写"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#为什么副本不提供读写"}},[s._v("#")]),s._v(" 为什么副本不提供读写")]),s._v(" "),t("p",[s._v("partition 和 消费组已经可以做到并发了.不需要副本增加复杂性.")]),s._v(" "),t("h3",{attrs:{id:"isr"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#isr"}},[s._v("#")]),s._v(" ISR")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[s._v("replica.lag.max.message "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 同步副本锁能落后的最大消息数,当副本的最大偏移量落后 leader 大于该值时就认为该副本不同步了.会从 ISR 移除,如果设置过小,会导致 follower 经常被提出 ISR,如果设置过大,则 leader 宕机会造成过多消息丢失.")]),s._v("\nreplica.lag.time.ms "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 默认 10s, 当 follower 超过时间没有发送 fetch 请求同步 leader 时就会认为不同步而被踢出 ISR.从时间维度避免生产者发送大量消息到 leader 导致 ISR 频繁收缩和扩张问题.")]),s._v("\nunclean.leader.election.enable "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 当 isr 为空,没有同步副本,leader 也挂了,允许非同步副本选出新 leader,提高可用性,但会造成消息丢失.")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("ul",[t("li",[s._v("leo 记录了日志的下一条消息偏移量")]),s._v(" "),t("li",[s._v("HW(保证消息一致性) 界定了消费者可见的消息.消费者可以消费小于 HW 的消息,而大于 HW 的消息将无法消费. HW 一定小于 LEO.消息被同步副本同步完成后才让消息可被消费.")])]),s._v(" "),t("p",[s._v("每个副本中都存有 LEO 和 HW.而 leader 副本中除了存储自身的 LEO 和 HW,还存储了其它 follower 的 LEO 和 HW,leader 需要保证 HW 是所有 ISR 副本集合中 LEO 最小的值.follwer 副本拉取消息后会用当前偏移量 +1 来更新 LEO,同时更新 leader 上该 follwer 的 LEO. 用 leader 的 HW 值和当前 LEO 的最小值来更新 HW.follwer 收到消息后 LEO+1, 取 LEO 和 ISR 副本中 LEO 的最小值更新 HW.")]),s._v(" "),t("h3",{attrs:{id:"leader-epoch-checkpoint-文件"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#leader-epoch-checkpoint-文件"}},[s._v("#")]),s._v(" leader-epoch-checkpoint 文件")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[s._v("版本号1 offset1\n版本号2 offset2\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("p",[s._v("每个副本日志目录下都有一个"),t("code",[s._v("leader-epoch-checkpoint")]),s._v("文件,保存 leader epoch 信息.包括 版本号,递增正整数,每次 leader 变更都会加 1.和一个 startoffset 为每一个版本 leader 写入的第一条消息的位移.")]),s._v(" "),t("h3",{attrs:{id:"分区划分"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#分区划分"}},[s._v("#")]),s._v(" 分区划分")]),s._v(" "),t("ol",[t("li",[s._v("如果指定了某个 partition 则写入")]),s._v(" "),t("li",[s._v("如果没指定 partition,但是设置了数据的 key,则根据 key 的值 hash 出一个 partition")]),s._v(" "),t("li",[s._v("如果没指定 partition,又没有设置 key,则轮询出一个 partition")])]),s._v(" "),t("h3",{attrs:{id:"如何保证数据不丢失"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如何保证数据不丢失"}},[s._v("#")]),s._v(" 如何保证数据不丢失")]),s._v(" "),t("p",[s._v("通过 ack 机制保证数据不丢失")]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("值")]),s._v(" "),t("th",[s._v("描述")]),s._v(" "),t("th",[s._v("默认")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("0")]),s._v(" "),t("td",[s._v("不需要等到集群返回,不确保消息发送成功")]),s._v(" "),t("td",[s._v("默认")])]),s._v(" "),t("tr",[t("td",[s._v("1")]),s._v(" "),t("td",[s._v("只要 leader 写入成功")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("all")]),s._v(" "),t("td",[s._v("所有 follower 都同步完成")]),s._v(" "),t("td")])])]),s._v(" "),t("h3",{attrs:{id:"kafka消息组成"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka消息组成"}},[s._v("#")]),s._v(" kafka消息组成")]),s._v(" "),t("ol",[t("li",[s._v("offset : 偏移量,占 8 个字节")]),s._v(" "),t("li",[s._v("size : 消息长度,占 4 个字节描述消息大小")]),s._v(" "),t("li",[s._v("message : key、value、key-length、value-length、crc(消息校验)、attribute(消息属性)")])]),s._v(" "),t("h3",{attrs:{id:"存储策略"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#存储策略"}},[s._v("#")]),s._v(" 存储策略")]),s._v(" "),t("p",[s._v("无论消息是否被消费,都会保存所有消息.")]),s._v(" "),t("ol",[t("li",[s._v("基于时间,默认 168 小时(7 天)")]),s._v(" "),t("li",[s._v("基于大小")])]),s._v(" "),t("h3",{attrs:{id:"查找数据"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#查找数据"}},[s._v("#")]),s._v(" 查找数据")]),s._v(" "),t("p",[s._v("segment + offset")]),s._v(" "),t("ol",[t("li",[s._v("先找到 offset 所在的 segment 文件(二分查找)")]),s._v(" "),t("li",[s._v("打开着到的 segment 的 index (存储 offset 对应 message 的物理偏移量) 计算相对 offset")]),s._v(" "),t("li",[s._v("找到物理偏移量,打开数据文件,扫描 message")])]),s._v(" "),t("h3",{attrs:{id:"元数据"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#元数据"}},[s._v("#")]),s._v(" 元数据")]),s._v(" "),t("p",[s._v("新版本中消费者消费到的 offset 直接维护在 __consumer_offsets topic 中,逐渐放弃 zk.")]),s._v(" "),t("h3",{attrs:{id:"mmap"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mmap"}},[s._v("#")]),s._v(" mmap")]),s._v(" "),t("p",[s._v("文件映射,系统向操作内存一样操作文件."),t("code",[s._v("producer.type")]),s._v("控制是不是主动 flush , 如果写入 mmap 立即 flush 然后返回则是同步,如果写入 mmap 后不调用 flush 则是异步(async), kafka 默认同步(sync), 虚拟内存直接映射到页缓存上,不需要从内核空间拷贝到用户空间再读取.")]),s._v(" "),t("h3",{attrs:{id:"零拷贝"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#零拷贝"}},[s._v("#")]),s._v(" 零拷贝")]),s._v(" "),t("p",[s._v("数据在内核实现输入输出.不需要拷贝到用户空间,sendfile 和 mmap 都是零拷贝到实现.")]),s._v(" "),t("p",[s._v("sendfile : 将页缓存数据直接拷贝到网卡相比 read + write 和 mmap + write 少了上下文和数据拷贝.")]),s._v(" "),t("h2",{attrs:{id:"zk"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#zk"}},[s._v("#")]),s._v(" zk")]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("角色")]),s._v(" "),t("th",[s._v("作用")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("leader")]),s._v(" "),t("td",[s._v("提供读写功能,负责将数据同步其他节点")])]),s._v(" "),t("tr",[t("td",[s._v("follower")]),s._v(" "),t("td",[s._v("提供读功能,写请求转发 leader 处理,leader 宕机后参与 leader 选举")])]),s._v(" "),t("tr",[t("td",[s._v("observer")]),s._v(" "),t("td",[s._v("与 follower 不同的是不参与选举")])]),s._v(" "),t("tr",[t("td",[s._v("looking")]),s._v(" "),t("td",[s._v("节点认为集群没有 leader 会进入 looking 状态,目的是查找或选举 leader")])])])]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("zab状态")]),s._v(" "),t("th",[s._v("作用")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("election")]),s._v(" "),t("td",[s._v("选举状态,会选举一个 leader")])]),s._v(" "),t("tr",[t("td",[s._v("discovery")]),s._v(" "),t("td",[s._v("响应 leader 心跳,检查 leader 是否修改,通过该步后选举的 leader 才能真正提供服务")])]),s._v(" "),t("tr",[t("td",[s._v("synchroniztion")]),s._v(" "),t("td",[s._v("整个集群都确认 leader 后将会把 leader 数据同步所有节点")])]),s._v(" "),t("tr",[t("td",[s._v("broadcast")]),s._v(" "),t("td",[s._v("广播状态,集群开始对外提供服务")])])])]),s._v(" "),t("p",[s._v("zxid : long(64) 位整数,分为纪元部分(当前属于哪个 leader 或者任期)和计数器部分,是一个全局有序数字,选举时先比较纪元然后比较 zxid 如果都相等则比较 serveid,配置集群时可以把性能好的 serveid 配置大些.")]),s._v(" "),t("h3",{attrs:{id:"zk-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#zk-2"}},[s._v("#")]),s._v(" zk")]),s._v(" "),t("p",[s._v("broker 发现、生产者发现、消费者发现、下线、controller 注册,旧版本存储消费者的 offset.")]),s._v(" "),t("h2",{attrs:{id:"异步消息乱序"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#异步消息乱序"}},[s._v("#")]),s._v(" 异步消息乱序")]),s._v(" "),t("h2",{attrs:{id:"使用场景"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#使用场景"}},[s._v("#")]),s._v(" 使用场景")]),s._v(" "),t("ol",[t("li",[s._v("多个定时任务")]),s._v(" "),t("li",[s._v("上游不关心下游执行结果")]),s._v(" "),t("li",[s._v("上游关心执行结果但是但是执行时间很长")])]),s._v(" "),t("h3",{attrs:{id:"reactor网络线程模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#reactor网络线程模型"}},[s._v("#")]),s._v(" reactor网络线程模型")]),s._v(" "),t("p",[t("img",{attrs:{src:e(510),alt:"kafka-reactor"}})]),s._v(" "),t("p",[s._v("客户端发送请求给 Acceptor , Acceptor 不会对处理请求,直接封装成 socketChannel 轮询发给 processor 线程(默认3个) 形成队列. io 线程池(默认8个)负责处理 request, 如果是写就写入磁盘,如果是读就返回结果, processor 会从response 中读取形影再返回给客户端.")]),s._v(" "),t("h2",{attrs:{id:"kafka长轮询"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka长轮询"}},[s._v("#")]),s._v(" kafka长轮询")]),s._v(" "),t("p",[s._v("在拉请求中有参数可以使消费者请求在长轮询中阻塞等待,消费者去 broker 拉消息,定义了一个超时时间如果有消息马上返回,如果没有消费者等着直到超时然后再发起拉消息请求.borker端如果请求过来有消息马上返回没消息就建立一个延迟操作等条件满足了再返回.")]),s._v(" "),t("h2",{attrs:{id:"rocketmq-3"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rocketmq-3"}},[s._v("#")]),s._v(" RocketMQ")]),s._v(" "),t("p",[s._v("将消息存入一个文件中,而 kafka 是将消息分 partition 存储.")]),s._v(" "),t("h2",{attrs:{id:"消息队列-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息队列-2"}},[s._v("#")]),s._v(" 消息队列")]),s._v(" "),t("p",[t("img",{attrs:{src:e(511),alt:"xiaoxiduilie"}})]),s._v(" "),t("p",[s._v("队列模型、和发布订阅模型 : 队列模型每条消息只能被一个消费者消费,发布订阅模型可以让一条消息被多个消费者消费,队列模型可以通过消息全量存储到多个队列解决一条消息被多个消费者消费的问题,")]),s._v(" "),t("h3",{attrs:{id:"可靠"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#可靠"}},[s._v("#")]),s._v(" 可靠")]),s._v(" "),t("p",[s._v("生产者需要处理 broker 响应出错要重试、报警等,broker 要控制响应时机单机情况下刷盘返回响应,集群多副本时至少发送两个副本再返回响应,消费这需要真正执行完业务逻辑后再返回给 broker.")]),s._v(" "),t("h3",{attrs:{id:"重复"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#重复"}},[s._v("#")]),s._v(" 重复")]),s._v(" "),t("p",[s._v("下游幂等")]),s._v(" "),t("h3",{attrs:{id:"幂等"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#幂等"}},[s._v("#")]),s._v(" 幂等")]),s._v(" "),t("p",[s._v("乐观锁,前置条件判断版本号、数据库唯一键、唯一ID等")]),s._v(" "),t("h3",{attrs:{id:"有序"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#有序"}},[s._v("#")]),s._v(" 有序")]),s._v(" "),t("p",[s._v("全局有序、局部有序")]),s._v(" "),t("h2",{attrs:{id:"消息队列-3"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息队列-3"}},[s._v("#")]),s._v(" 消息队列")]),s._v(" "),t("ol",[t("li",[s._v("确认")]),s._v(" "),t("li",[s._v("重传")]),s._v(" "),t("li",[s._v("幂等 : 去重,检查序列号 n 是否已经被处理")]),s._v(" "),t("li",[s._v("顺序 : 如果收到的消息序列号不连续,接收方可以将其放入重新排序缓存区")])]),s._v(" "),t("h3",{attrs:{id:"如何保证消息必达"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如何保证消息必达"}},[s._v("#")]),s._v(" 如何保证消息必达")]),s._v(" "),t("ol",[t("li",[s._v("消息落地")]),s._v(" "),t("li",[s._v("超时、重传、确认")])]),s._v(" "),t("h3",{attrs:{id:"如何保证幂等性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如何保证幂等性"}},[s._v("#")]),s._v(" 如何保证幂等性")]),s._v(" "),t("h3",{attrs:{id:"发送端到-server-的幂等"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#发送端到-server-的幂等"}},[s._v("#")]),s._v(" 发送端到 server 的幂等")]),s._v(" "),t("ol",[t("li",[s._v("发送端将消息发送给服务端")]),s._v(" "),t("li",[s._v("服务端将消息落地")]),s._v(" "),t("li",[s._v("服务端回 ack 给发送端")])]),s._v(" "),t("p",[s._v("如果 3 丢失,发送端会超时重发, 为了避免 2 落地重复消息,消息内部生成唯一 ID (全局唯一,MQ 生成,具备业务无关性,对发送方和接收方屏蔽)作为去重和幂等依据.")]),s._v(" "),t("h3",{attrs:{id:"server-到接收端端幂等"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#server-到接收端端幂等"}},[s._v("#")]),s._v(" server 到接收端端幂等")]),s._v(" "),t("ol",[t("li",[s._v("服务端将消息发送给接收端")]),s._v(" "),t("li",[s._v("接收端回 ack 给服务端")]),s._v(" "),t("li",[s._v("服务端将落地消息删除")])]),s._v(" "),t("p",[s._v("如果 2 丢失,可能回超时重发,导致接收方即业务方重复消费,为保证业务幂等性,消息体中必须有一个 biz_id (同一业务场景全局唯一、由业务发送方生成,业务相关,对 MQ 透明、由业务消费方负责判重,保证幂等),有了业务 ID 就能保证消费业务方即使收到重复消息,也只有一条被消费.")]),s._v(" "),t("h2",{attrs:{id:"kafka配置文件"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka配置文件"}},[s._v("#")]),s._v(" kafka配置文件")]),s._v(" "),t("h3",{attrs:{id:"producer-properties"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#producer-properties"}},[s._v("#")]),s._v(" producer.properties")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#指定kafka节点列表，用于获取metadata，不必全部指定")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#需要kafka的服务器地址，来获取每一个topic的分片数等元数据信息。")]),s._v("\nmetadata.broker.list"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("kafka01:9092,kafka02:9092,kafka03:9092\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#生产者生产的消息被发送到哪个block，需要一个分组策略。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#指定分区处理类。默认kafka.producer.DefaultPartitioner，表通过key哈希到对应分区")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#partitioner.class=kafka.producer.DefaultPartitioner")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#生产者生产的消息可以通过一定的压缩策略（或者说压缩算法）来压缩。消息被压缩后发送到broker集群，#而broker集群是不会进行解压缩的，broker集群只会把消息发送到消费者集群，然后由消费者来解压缩。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#是否压缩，默认0表示不压缩，1表示用gzip压缩，2表示用snappy压缩。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#压缩后消息中会有头来指明消息压缩类型，故在消费者端消息解压是透明的无需指定。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#文本数据会以1比10或者更高的压缩比进行压缩。")]),s._v("\ncompression.codec"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("none\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#指定序列化处理类，消息在网络上传输就需要序列化，它有String、数组等许多种实现。")]),s._v("\nserializer.class"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("kafka.serializer.DefaultEncoder\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#如果要压缩消息，这里指定哪些topic要压缩消息，默认empty，表示不压缩。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#如果上面启用了压缩，那么这里就需要设置")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#compressed.topics=")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#这是消息的确认机制，默认值是0。在面试中常被问到。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#producer有个ack参数，有三个值，分别代表：")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#（1）不在乎是否写入成功；")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#（2）写入leader成功；")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#（3）写入leader和所有副本都成功；")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#要求非常可靠的话可以牺牲性能设置成最后一种。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#为了保证消息不丢失，至少要设置为1，也就")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#是说至少保证leader将消息保存成功。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#设置发送数据是否需要服务端的反馈,有三个值0,1,-1，分别代表3种状态：")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#0: producer不会等待broker发送ack。生产者只要把消息发送给broker之后，就认为发送成功了，这是第1种情况；")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#1: 当leader接收到消息之后发送ack。生产者把消息发送到broker之后，并且消息被写入到本地文件，才认为发送成功，这是第二种情况；#-1: 当所有的follower都同步消息成功后发送ack。不仅是主的分区将消息保存成功了，#而且其所有的分区的副本数也都同步好了，才会被认为发动成功，这是第3种情况。")]),s._v("\nrequest.required.acks"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#broker必须在该时间范围之内给出反馈，否则失败。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#在向producer发送ack之前,broker允许等待的最大时间 ，如果超时,")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#broker将会向producer发送一个error ACK.意味着上一次消息因为某种原因")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#未能成功(比如follower未能同步成功)")]),s._v("\nrequest.timeout.ms"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10000")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#生产者将消息发送到broker，有两种方式，一种是同步，表示生产者发送一条，broker就接收一条；#还有一种是异步，表示生产者积累到一批的消息，装到一个池子里面缓存起来，再发送给broker，#这个池子不会无限缓存消息，在下面，它分别有一个时间限制（时间阈值）和一个数量限制（数量阈值）的参数供我们来设置。#一般我们会选择异步。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v('#同步还是异步发送消息，默认“sync”表同步，"async"表异步。异步可以提高发送吞吐量,#也意味着消息将会在本地buffer中,并适时批量发送，但是也可能导致丢失未发送过去的消息')]),s._v("\nproducer.type"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("sync\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#在async模式下,当message被缓存的时间超过此值后,将会批量发送给broker,")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#默认为5000ms")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#此值和batch.num.messages协同工作.")]),s._v("\nqueue.buffering.max.ms "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5000")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#异步情况下，缓存中允许存放消息数量的大小。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#在async模式下,producer端允许buffer的最大消息量")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#无论如何,producer都无法尽快的将消息发送给broker,从而导致消息在producer端大量沉积")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#此时,如果消息的条数达到阀值,将会导致producer端阻塞或者消息被抛弃，默认为10000条消息。")]),s._v("\nqueue.buffering.max.messages"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("20000")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#如果是异步，指定每次批量发送数据量，默认为200")]),s._v("\nbatch.num.messages"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("500")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#在生产端的缓冲池中，消息发送出去之后，在没有收到确认之前，该缓冲池中的消息是不能被删除的，#但是生产者一直在生产消息，这个时候缓冲池可能会被撑爆，所以这就需要有一个处理的策略。#有两种处理方式，一种是让生产者先别生产那么快，阻塞一下，等会再生产；另一种是将缓冲池中的消息清空。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v('#当消息在producer端沉积的条数达到"queue.buffering.max.meesages"后阻塞一定时间后,#队列仍然没有enqueue(producer仍然没有发送出任何消息)')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v('#此时producer可以继续阻塞或者将消息抛弃,此timeout值用于控制"阻塞"的时间')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#-1: 不限制阻塞超时时间，让produce一直阻塞,这个时候消息就不会被抛弃")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#0: 立即清空队列,消息被抛弃")]),s._v("\nqueue.enqueue.timeout.ms"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("-1\n\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#当producer接收到error ACK,或者没有接收到ACK时,允许消息重发的次数")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#因为broker并没有完整的机制来避免消息重复,所以当网络异常时(比如ACK丢失)")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#有可能导致broker接收到重复的消息,默认值为3.")]),s._v("\nmessage.send.max.retries"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#producer刷新topic metada的时间间隔,producer需要知道partition leader")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#的位置,以及当前topic的情况")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#因此producer需要一个机制来获取最新的metadata,当producer遇到特定错误时,")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#将会立即刷新")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#(比如topic失效,partition丢失,leader失效等),此外也可以通过此参数来配置")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#额外的刷新机制，默认值600000")]),s._v("\ntopic.metadata.refresh.interval.ms"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("60000")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br"),t("span",{staticClass:"line-number"},[s._v("52")]),t("br"),t("span",{staticClass:"line-number"},[s._v("53")]),t("br"),t("span",{staticClass:"line-number"},[s._v("54")]),t("br"),t("span",{staticClass:"line-number"},[s._v("55")]),t("br"),t("span",{staticClass:"line-number"},[s._v("56")]),t("br"),t("span",{staticClass:"line-number"},[s._v("57")]),t("br"),t("span",{staticClass:"line-number"},[s._v("58")]),t("br"),t("span",{staticClass:"line-number"},[s._v("59")]),t("br"),t("span",{staticClass:"line-number"},[s._v("60")]),t("br"),t("span",{staticClass:"line-number"},[s._v("61")]),t("br"),t("span",{staticClass:"line-number"},[s._v("62")]),t("br"),t("span",{staticClass:"line-number"},[s._v("63")]),t("br"),t("span",{staticClass:"line-number"},[s._v("64")]),t("br"),t("span",{staticClass:"line-number"},[s._v("65")]),t("br"),t("span",{staticClass:"line-number"},[s._v("66")]),t("br"),t("span",{staticClass:"line-number"},[s._v("67")]),t("br"),t("span",{staticClass:"line-number"},[s._v("68")]),t("br"),t("span",{staticClass:"line-number"},[s._v("69")]),t("br"),t("span",{staticClass:"line-number"},[s._v("70")]),t("br"),t("span",{staticClass:"line-number"},[s._v("71")]),t("br"),t("span",{staticClass:"line-number"},[s._v("72")]),t("br"),t("span",{staticClass:"line-number"},[s._v("73")]),t("br"),t("span",{staticClass:"line-number"},[s._v("74")]),t("br"),t("span",{staticClass:"line-number"},[s._v("75")]),t("br"),t("span",{staticClass:"line-number"},[s._v("76")]),t("br"),t("span",{staticClass:"line-number"},[s._v("77")]),t("br")])]),t("h3",{attrs:{id:"consumer-properties"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#consumer-properties"}},[s._v("#")]),s._v(" consumer.properties")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#指定kafka节点列表，用于获取metadata，不必全部指定")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#需要kafka的服务器地址，来获取每一个topic的分片数等元数据信息。")]),s._v("\nmetadata.broker.list"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("kafka01:9092,kafka02:9092,kafka03:9092\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#生产者生产的消息被发送到哪个block，需要一个分组策略。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#指定分区处理类。默认kafka.producer.DefaultPartitioner，表通过key哈希到对应分区")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#partitioner.class=kafka.producer.DefaultPartitioner")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#生产者生产的消息可以通过一定的压缩策略（或者说压缩算法）来压缩。消息被压缩后发送到broker集群，#而broker集群是不会进行解压缩的，broker集群只会把消息发送到消费者集群，然后由消费者来解压缩。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#是否压缩，默认0表示不压缩，1表示用gzip压缩，2表示用snappy压缩。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#压缩后消息中会有头来指明消息压缩类型，故在消费者端消息解压是透明的无需指定。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#文本数据会以1比10或者更高的压缩比进行压缩。")]),s._v("\ncompression.codec"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("none\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#指定序列化处理类，消息在网络上传输就需要序列化，它有String、数组等许多种实现。")]),s._v("\nserializer.class"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("kafka.serializer.DefaultEncoder\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#如果要压缩消息，这里指定哪些topic要压缩消息，默认empty，表示不压缩。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#如果上面启用了压缩，那么这里就需要设置")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#compressed.topics=")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#这是消息的确认机制，默认值是0。在面试中常被问到。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#producer有个ack参数，有三个值，分别代表：")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#（1）不在乎是否写入成功；")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#（2）写入leader成功；")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#（3）写入leader和所有副本都成功；")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#要求非常可靠的话可以牺牲性能设置成最后一种。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#为了保证消息不丢失，至少要设置为1，也就")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#是说至少保证leader将消息保存成功。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#设置发送数据是否需要服务端的反馈,有三个值0,1,-1，分别代表3种状态：")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#0: producer不会等待broker发送ack。生产者只要把消息发送给broker之后，就认为发送成功了，这是第1种情况；")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#1: 当leader接收到消息之后发送ack。生产者把消息发送到broker之后，并且消息被写入到本地文件，才认为发送成功，这是第二种情况；#-1: 当所有的follower都同步消息成功后发送ack。不仅是主的分区将消息保存成功了，#而且其所有的分区的副本数也都同步好了，才会被认为发动成功，这是第3种情况。")]),s._v("\nrequest.required.acks"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#broker必须在该时间范围之内给出反馈，否则失败。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#在向producer发送ack之前,broker允许等待的最大时间 ，如果超时,")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#broker将会向producer发送一个error ACK.意味着上一次消息因为某种原因")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#未能成功(比如follower未能同步成功)")]),s._v("\nrequest.timeout.ms"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10000")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#生产者将消息发送到broker，有两种方式，一种是同步，表示生产者发送一条，broker就接收一条；#还有一种是异步，表示生产者积累到一批的消息，装到一个池子里面缓存起来，再发送给broker，#这个池子不会无限缓存消息，在下面，它分别有一个时间限制（时间阈值）和一个数量限制（数量阈值）的参数供我们来设置。#一般我们会选择异步。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v('#同步还是异步发送消息，默认“sync”表同步，"async"表异步。异步可以提高发送吞吐量,#也意味着消息将会在本地buffer中,并适时批量发送，但是也可能导致丢失未发送过去的消息')]),s._v("\nproducer.type"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("sync\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#在async模式下,当message被缓存的时间超过此值后,将会批量发送给broker,")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#默认为5000ms")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#此值和batch.num.messages协同工作.")]),s._v("\nqueue.buffering.max.ms "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5000")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#异步情况下，缓存中允许存放消息数量的大小。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#在async模式下,producer端允许buffer的最大消息量")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#无论如何,producer都无法尽快的将消息发送给broker,从而导致消息在producer端大量沉积")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#此时,如果消息的条数达到阀值,将会导致producer端阻塞或者消息被抛弃，默认为10000条消息。")]),s._v("\nqueue.buffering.max.messages"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("20000")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#如果是异步，指定每次批量发送数据量，默认为200")]),s._v("\nbatch.num.messages"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("500")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#在生产端的缓冲池中，消息发送出去之后，在没有收到确认之前，该缓冲池中的消息是不能被删除的，#但是生产者一直在生产消息，这个时候缓冲池可能会被撑爆，所以这就需要有一个处理的策略。#有两种处理方式，一种是让生产者先别生产那么快，阻塞一下，等会再生产；另一种是将缓冲池中的消息清空。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v('#当消息在producer端沉积的条数达到"queue.buffering.max.meesages"后阻塞一定时间后,#队列仍然没有enqueue(producer仍然没有发送出任何消息)')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v('#此时producer可以继续阻塞或者将消息抛弃,此timeout值用于控制"阻塞"的时间')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#-1: 不限制阻塞超时时间，让produce一直阻塞,这个时候消息就不会被抛弃")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#0: 立即清空队列,消息被抛弃")]),s._v("\nqueue.enqueue.timeout.ms"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("-1\n\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#当producer接收到error ACK,或者没有接收到ACK时,允许消息重发的次数")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#因为broker并没有完整的机制来避免消息重复,所以当网络异常时(比如ACK丢失)")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#有可能导致broker接收到重复的消息,默认值为3.")]),s._v("\nmessage.send.max.retries"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#producer刷新topic metada的时间间隔,producer需要知道partition leader")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#的位置,以及当前topic的情况")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#因此producer需要一个机制来获取最新的metadata,当producer遇到特定错误时,")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#将会立即刷新")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#(比如topic失效,partition丢失,leader失效等),此外也可以通过此参数来配置")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#额外的刷新机制，默认值600000")]),s._v("\ntopic.metadata.refresh.interval.ms"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("60000")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br"),t("span",{staticClass:"line-number"},[s._v("52")]),t("br"),t("span",{staticClass:"line-number"},[s._v("53")]),t("br"),t("span",{staticClass:"line-number"},[s._v("54")]),t("br"),t("span",{staticClass:"line-number"},[s._v("55")]),t("br"),t("span",{staticClass:"line-number"},[s._v("56")]),t("br"),t("span",{staticClass:"line-number"},[s._v("57")]),t("br"),t("span",{staticClass:"line-number"},[s._v("58")]),t("br"),t("span",{staticClass:"line-number"},[s._v("59")]),t("br"),t("span",{staticClass:"line-number"},[s._v("60")]),t("br"),t("span",{staticClass:"line-number"},[s._v("61")]),t("br"),t("span",{staticClass:"line-number"},[s._v("62")]),t("br"),t("span",{staticClass:"line-number"},[s._v("63")]),t("br"),t("span",{staticClass:"line-number"},[s._v("64")]),t("br"),t("span",{staticClass:"line-number"},[s._v("65")]),t("br"),t("span",{staticClass:"line-number"},[s._v("66")]),t("br"),t("span",{staticClass:"line-number"},[s._v("67")]),t("br"),t("span",{staticClass:"line-number"},[s._v("68")]),t("br"),t("span",{staticClass:"line-number"},[s._v("69")]),t("br"),t("span",{staticClass:"line-number"},[s._v("70")]),t("br"),t("span",{staticClass:"line-number"},[s._v("71")]),t("br"),t("span",{staticClass:"line-number"},[s._v("72")]),t("br"),t("span",{staticClass:"line-number"},[s._v("73")]),t("br"),t("span",{staticClass:"line-number"},[s._v("74")]),t("br"),t("span",{staticClass:"line-number"},[s._v("75")]),t("br"),t("span",{staticClass:"line-number"},[s._v("76")]),t("br"),t("span",{staticClass:"line-number"},[s._v("77")]),t("br")])]),t("h3",{attrs:{id:"server-properties"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#server-properties"}},[s._v("#")]),s._v(" server.properties")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#消费者集群通过连接Zookeeper来找到broker。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#zookeeper连接服务器地址")]),s._v("\nzookeeper.connect"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("zk01:2181,zk02:2181,zk03:2181\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#zookeeper的session过期时间，默认5000ms，用于检测消费者是否挂掉")]),s._v("\nzookeeper.session.timeout.ms"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5000")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#当消费者挂掉，其他消费者要等该指定时间才能检查到并且触发重新负载均衡")]),s._v("\nzookeeper.connection.timeout.ms"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10000")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#这是一个时间阈值。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#指定多久消费者更新offset到zookeeper中。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#注意offset更新时基于time而不是每次获得的消息。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#一旦在更新zookeeper发生异常并重启，将可能拿到已拿到过的消息")]),s._v("\nzookeeper.sync.time.ms"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#指定消费")]),s._v("\ngroup.id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("xxxxx\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#这是一个数量阈值，经测试是500条。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#当consumer消费一定量的消息之后,将会自动向zookeeper提交offset信息#注意offset信息并不是每消费一次消息就向zk提交")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#一次,而是现在本地保存(内存),并定期提交,默认为true")]),s._v("\nauto.commit.enable"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("true\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 自动更新时间。默认60 * 1000")]),s._v("\nauto.commit.interval.ms"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 当前consumer的标识,可以设定,也可以有系统生成,")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#主要用来跟踪消息消费情况,便于观察")]),s._v("\nconusmer.id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("xxx\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 消费者客户端编号，用于区分不同客户端，默认客户端程序自动产生")]),s._v("\nclient.id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("xxxx\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 最大取多少块缓存到消费者(默认10)")]),s._v("\nqueued.max.message.chunks"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("50")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 当有新的consumer加入到group时,将会reblance,此后将会")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#有partitions的消费端迁移到新  的consumer上,如果一个")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#consumer获得了某个partition的消费权限,那么它将会向zk")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v('#注册 "Partition Owner registry"节点信息,但是有可能')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#此时旧的consumer尚没有释放此节点, 此值用于控制,")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#注册节点的重试次数.")]),s._v("\nrebalance.max.retries"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#每拉取一批消息的最大字节数")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#获取消息的最大尺寸,broker不会像consumer输出大于")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#此值的消息chunk 每次feth将得到多条消息,此值为总大小,")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#提升此值,将会消耗更多的consumer端内存")]),s._v("\nfetch.min.bytes"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6553600")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#当消息的尺寸不足时,server阻塞的时间,如果超时,")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#消息将立即发送给consumer")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#数据一批一批到达，如果每一批是10条消息，如果某一批还")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#不到10条，但是超时了，也会立即发送给consumer。")]),s._v("\nfetch.wait.max.ms"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5000")]),s._v("\nsocket.receive.buffer.bytes"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("655360")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 如果zookeeper没有offset值或offset值超出范围。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#那么就给个初始的offset。有smallest、largest、")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#anything可选，分别表示给当前最小的offset、")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#当前最大的offset、抛异常。默认largest")]),s._v("\nauto.offset.reset"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("smallest\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 指定序列化处理类")]),s._v("\nderializer.class"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("kafka.serializer.DefaultDecoder\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br"),t("span",{staticClass:"line-number"},[s._v("52")]),t("br"),t("span",{staticClass:"line-number"},[s._v("53")]),t("br"),t("span",{staticClass:"line-number"},[s._v("54")]),t("br"),t("span",{staticClass:"line-number"},[s._v("55")]),t("br"),t("span",{staticClass:"line-number"},[s._v("56")]),t("br"),t("span",{staticClass:"line-number"},[s._v("57")]),t("br"),t("span",{staticClass:"line-number"},[s._v("58")]),t("br"),t("span",{staticClass:"line-number"},[s._v("59")]),t("br"),t("span",{staticClass:"line-number"},[s._v("60")]),t("br"),t("span",{staticClass:"line-number"},[s._v("61")]),t("br"),t("span",{staticClass:"line-number"},[s._v("62")]),t("br"),t("span",{staticClass:"line-number"},[s._v("63")]),t("br"),t("span",{staticClass:"line-number"},[s._v("64")]),t("br"),t("span",{staticClass:"line-number"},[s._v("65")]),t("br"),t("span",{staticClass:"line-number"},[s._v("66")]),t("br")])]),t("h2",{attrs:{id:"kafka-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka-2"}},[s._v("#")]),s._v(" kafka")]),s._v(" "),t("h3",{attrs:{id:"优点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#优点"}},[s._v("#")]),s._v(" 优点")]),s._v(" "),t("ol",[t("li",[s._v("顺序写 : 写数据时直接追加文件末尾")]),s._v(" "),t("li",[s._v("mmap : 数据不实时写入磁盘,提高 io 效率")]),s._v(" "),t("li",[s._v("零拷贝 : 读数据时使用 sendfile ,磁盘文件读到 os 内核缓冲区直接转到 socket buffer 进行网络发送")]),s._v(" "),t("li",[s._v("批量压缩,批量发送")])]),s._v(" "),t("h3",{attrs:{id:"丢失消息"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#丢失消息"}},[s._v("#")]),s._v(" 丢失消息")]),s._v(" "),t("ol",[t("li",[s._v("producer 丢失消息 : 调用 send 方法时由于网络原因发送失败, 解决方法 : 设置 restries 为一个合适的值,一般为3,重试时间间隔不能太小,避免网络一次波动的区间就把三次重试用完了")]),s._v(" "),t("li",[s._v("consumer 丢失消息 : 自动提交 offset 时可能未来得及处理消息,offset就被提交了. 解决方法 : 关闭自动提交,消费完成后手动提交 offset")]),s._v(" "),t("li",[s._v("brocker 丢失消息 : leader 所在副本宕机, follower 副本还没完全同步 leader\n"),t("ol",[t("li",[s._v("设置 acks = -1 或 all 保证 follower 副本写入消息")]),s._v(" "),t("li",[s._v("保证分区至少有 3 个副本,冗余消息"),t("code",[s._v("replication.fator > 3")])]),s._v(" "),t("li",[s._v("消息至少写入 2 个副本才能认为成功"),t("code",[s._v("min.insync.replicas > 1")])]),s._v(" "),t("li",[s._v("避免从 LSR 中选举 leader"),t("code",[s._v("unclean.leader.election.enbale = false")])])])])]),s._v(" "),t("h3",{attrs:{id:"一个-partition-只能被消费组中的一个消费者实例消费"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#一个-partition-只能被消费组中的一个消费者实例消费"}},[s._v("#")]),s._v(" 一个 partition 只能被消费组中的一个消费者实例消费")]),s._v(" "),t("p",[s._v("要在 partition 级别提供顺序消费,如果多个 consumer 消费一个 partition,即使 kafka 是顺序分发数据的,但由于网络延迟等情况, consumer 并不能保证按 kafka 的分发顺序接收到数据,这样达到顺序消费就无法保证.")]),s._v(" "),t("p",[s._v("通过二分查找定位消息在哪个 segment.对每个 segment 创建索引文件,每条记录是一个 kv 组(k 是消息 offset,v是 segment 中的偏移量)")]),s._v(" "),t("h3",{attrs:{id:"查询过程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#查询过程"}},[s._v("#")]),s._v(" 查询过程")]),s._v(" "),t("ol",[t("li",[s._v("利用二分查找找到消息的 segment 文件")]),s._v(" "),t("li",[s._v("读取 index 文件找到 segment 中的位置")]),s._v(" "),t("li",[s._v("读取 segment 文件中对应位置数据")])]),s._v(" "),t("h3",{attrs:{id:"稀疏索引"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#稀疏索引"}},[s._v("#")]),s._v(" 稀疏索引")]),s._v(" "),t("p",[s._v("并不是所有消息都会在 index 文件中记录 position,每间隔 N 条消息记录一条.虽然不能查到精确位置,但可以利用二分查找,找到距离消息最近的消息的位置")]),s._v(" "),t("h2",{attrs:{id:"pulsar"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#pulsar"}},[s._v("#")]),s._v(" pulsar")]),s._v(" "),t("p",[s._v("解决 kafka 扩容难度大问题,将服务层和存储层解藕,无状态的 broker 负责数据服务, bookie(bookeeper系统上的节点) 节点负责数据存储.计算、存储分离的消息系统")]),s._v(" "),t("blockquote",[t("p",[s._v("bookeeper 为日志存储打造的系统")])]),s._v(" "),t("p",[s._v("broker是无状态的用户消息到达时调用 bookeeper 接口写数据,要查询数据时调 bookeeper 接口查数据,同时做一些缓存.依赖 zookeeper 保存元数据的关系.虽然 broker 是无状态的但是只有将消息发送到同一个 broker 才能保证消息顺序写入.即每个 partition 生产必须对应同一台 broker.当某台 broker 挂了,可以立刻把 partition 对应的 broker 切换到另一个 broker 上,只要保证只有一个 broker 对 topic-partition-x 有写权限就行.不会发生数据迁移.")]),s._v(" "),t("h3",{attrs:{id:"写数据"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#写数据"}},[s._v("#")]),s._v(" 写数据")]),s._v(" "),t("ol",[t("li",[s._v("节点数 n : bookeeper 集群到 bookie 数")]),s._v(" "),t("li",[s._v("副本数 m : 某一个 ledger 会写入到 n 个 bookie 中的 m 个里,即 m 个副本")]),s._v(" "),t("li",[s._v("确认写入数 t : 每次向 ledger 写入数据时(并发写入到 m 个 bookie) 需要确保收到 t 个 ack 才返回成功.")])]),s._v(" "),t("blockquote",[t("p",[s._v("相当于把 kafka 的某个 partition 的 segment 均匀的分布到了多个存储节点上.扩容时快速添加机器,让新的 segment 存储到合适的 bookie 上,只要记住 segment 和 bookie 的关系就可以了.")])]),s._v(" "),t("h3",{attrs:{id:"消费模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消费模型"}},[s._v("#")]),s._v(" 消费模型")]),s._v(" "),t("p",[s._v("kafka 一个 partition 对应一个 consumer. pulsar 通过 subscription 支持 4 种消费方式.")]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("消费模式")]),s._v(" "),t("th",[s._v("备注")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("exclusive")]),s._v(" "),t("td",[s._v("消费组里仅有一个 consumer 能够消费,其它根本连不上 pulsar")])]),s._v(" "),t("tr",[t("td",[s._v("failover")]),s._v(" "),t("td",[s._v("消费组里的每个消费者都能连上 partition 所在的 broker,但仅有一个能消费到数据,如果挂了,会从其它消费者中选举")])]),s._v(" "),t("tr",[t("td",[s._v("shared")]),s._v(" "),t("td",[s._v("消费者中的所有消费者都能消费 topic 下所有 patition,消息以 round-robin (循环) 方式分发")])]),s._v(" "),t("tr",[t("td",[s._v("key-shard")]),s._v(" "),t("td",[s._v("消费者中的所有消费者都能消费 topic 下所有 patition,但是带有相同 key 的消息会保证发送给同一个消费者")])])])])])}),[],!1,null,null,null);a.default=r.exports}}]);